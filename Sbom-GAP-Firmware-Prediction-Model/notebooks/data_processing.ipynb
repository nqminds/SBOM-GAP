{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97c3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a4a3ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nvdcve-1.1-2002.json.gz...\n",
      "Extracting nvdcve-1.1-2002.json.gz...\n",
      "Extracted nvdcve-1.1-2002.json to folder ../data/CVEs/2002.\n",
      "\n",
      "Downloading nvdcve-1.1-2003.json.gz...\n",
      "Extracting nvdcve-1.1-2003.json.gz...\n",
      "Extracted nvdcve-1.1-2003.json to folder ../data/CVEs/2003.\n",
      "\n",
      "Downloading nvdcve-1.1-2004.json.gz...\n",
      "Extracting nvdcve-1.1-2004.json.gz...\n",
      "Extracted nvdcve-1.1-2004.json to folder ../data/CVEs/2004.\n",
      "\n",
      "Downloading nvdcve-1.1-2005.json.gz...\n",
      "Extracting nvdcve-1.1-2005.json.gz...\n",
      "Extracted nvdcve-1.1-2005.json to folder ../data/CVEs/2005.\n",
      "\n",
      "Downloading nvdcve-1.1-2006.json.gz...\n",
      "Extracting nvdcve-1.1-2006.json.gz...\n",
      "Extracted nvdcve-1.1-2006.json to folder ../data/CVEs/2006.\n",
      "\n",
      "Downloading nvdcve-1.1-2007.json.gz...\n",
      "Extracting nvdcve-1.1-2007.json.gz...\n",
      "Extracted nvdcve-1.1-2007.json to folder ../data/CVEs/2007.\n",
      "\n",
      "Downloading nvdcve-1.1-2008.json.gz...\n",
      "Extracting nvdcve-1.1-2008.json.gz...\n",
      "Extracted nvdcve-1.1-2008.json to folder ../data/CVEs/2008.\n",
      "\n",
      "Downloading nvdcve-1.1-2009.json.gz...\n",
      "Extracting nvdcve-1.1-2009.json.gz...\n",
      "Extracted nvdcve-1.1-2009.json to folder ../data/CVEs/2009.\n",
      "\n",
      "Downloading nvdcve-1.1-2010.json.gz...\n",
      "Extracting nvdcve-1.1-2010.json.gz...\n",
      "Extracted nvdcve-1.1-2010.json to folder ../data/CVEs/2010.\n",
      "\n",
      "Downloading nvdcve-1.1-2011.json.gz...\n",
      "Extracting nvdcve-1.1-2011.json.gz...\n",
      "Extracted nvdcve-1.1-2011.json to folder ../data/CVEs/2011.\n",
      "\n",
      "Downloading nvdcve-1.1-2012.json.gz...\n",
      "Extracting nvdcve-1.1-2012.json.gz...\n",
      "Extracted nvdcve-1.1-2012.json to folder ../data/CVEs/2012.\n",
      "\n",
      "Downloading nvdcve-1.1-2013.json.gz...\n",
      "Extracting nvdcve-1.1-2013.json.gz...\n",
      "Extracted nvdcve-1.1-2013.json to folder ../data/CVEs/2013.\n",
      "\n",
      "Downloading nvdcve-1.1-2014.json.gz...\n",
      "Extracting nvdcve-1.1-2014.json.gz...\n",
      "Extracted nvdcve-1.1-2014.json to folder ../data/CVEs/2014.\n",
      "\n",
      "Downloading nvdcve-1.1-2015.json.gz...\n",
      "Extracting nvdcve-1.1-2015.json.gz...\n",
      "Extracted nvdcve-1.1-2015.json to folder ../data/CVEs/2015.\n",
      "\n",
      "Downloading nvdcve-1.1-2016.json.gz...\n",
      "Extracting nvdcve-1.1-2016.json.gz...\n",
      "Extracted nvdcve-1.1-2016.json to folder ../data/CVEs/2016.\n",
      "\n",
      "Downloading nvdcve-1.1-2017.json.gz...\n",
      "Extracting nvdcve-1.1-2017.json.gz...\n",
      "Extracted nvdcve-1.1-2017.json to folder ../data/CVEs/2017.\n",
      "\n",
      "Downloading nvdcve-1.1-2018.json.gz...\n",
      "Extracting nvdcve-1.1-2018.json.gz...\n",
      "Extracted nvdcve-1.1-2018.json to folder ../data/CVEs/2018.\n",
      "\n",
      "Downloading nvdcve-1.1-2019.json.gz...\n",
      "Extracting nvdcve-1.1-2019.json.gz...\n",
      "Extracted nvdcve-1.1-2019.json to folder ../data/CVEs/2019.\n",
      "\n",
      "Downloading nvdcve-1.1-2020.json.gz...\n",
      "Extracting nvdcve-1.1-2020.json.gz...\n",
      "Extracted nvdcve-1.1-2020.json to folder ../data/CVEs/2020.\n",
      "\n",
      "Downloading nvdcve-1.1-2021.json.gz...\n",
      "Extracting nvdcve-1.1-2021.json.gz...\n",
      "Extracted nvdcve-1.1-2021.json to folder ../data/CVEs/2021.\n",
      "\n",
      "Downloading nvdcve-1.1-2022.json.gz...\n",
      "Extracting nvdcve-1.1-2022.json.gz...\n",
      "Extracted nvdcve-1.1-2022.json to folder ../data/CVEs/2022.\n",
      "\n",
      "Downloading nvdcve-1.1-2023.json.gz...\n",
      "Extracting nvdcve-1.1-2023.json.gz...\n",
      "Extracted nvdcve-1.1-2023.json to folder ../data/CVEs/2023.\n",
      "\n",
      "Downloading nvdcve-1.1-2024.json.gz...\n",
      "Extracting nvdcve-1.1-2024.json.gz...\n",
      "Extracted nvdcve-1.1-2024.json to folder ../data/CVEs/2024.\n",
      "\n",
      "Download and extraction completed.\n"
     ]
    }
   ],
   "source": [
    "def download_and_extract_cve_data(start_year=2002, end_year=2024, base_url=\"https://nvd.nist.gov/feeds/json/cve/1.1/\"):\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Construct the download URL for each year\n",
    "        url = f\"{base_url}nvdcve-1.1-{year}.json.gz\"\n",
    "        folder_name = f\"../data/CVEs/{str(year)}\"\n",
    "        file_name = f\"nvdcve-1.1-{year}.json.gz\"\n",
    "        output_json = f\"nvdcve-1.1-{year}.json\"\n",
    "        \n",
    "        # Create a folder for each year if it doesn't exist\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        \n",
    "        # Download the file\n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        \n",
    "        # Save the .gz file\n",
    "        gz_path = os.path.join(folder_name, file_name)\n",
    "        with open(gz_path, 'wb') as gz_file:\n",
    "            gz_file.write(response.content)\n",
    "        \n",
    "        # Unzip the file\n",
    "        print(f\"Extracting {file_name}...\")\n",
    "        json_path = os.path.join(folder_name, output_json)\n",
    "        with gzip.open(gz_path, 'rb') as f_in:\n",
    "            with open(json_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        print(f\"Extracted {output_json} to folder {folder_name}.\\n\")\n",
    "    \n",
    "    print(\"Download and extraction completed.\")\n",
    "\n",
    "# Example usage:\n",
    "download_and_extract_cve_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88cc0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to ../data/CPEs/cpe_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_cpe_data(xml_file, output_csv):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract the timestamp from the \"generator\" section\n",
    "    generator = root.find(\".//{http://cpe.mitre.org/dictionary/2.0}generator\")\n",
    "    release_date = generator.find(\"{http://cpe.mitre.org/dictionary/2.0}timestamp\").text if generator is not None else \"N/A\"\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['cpe_name', 'title', 'notes', 'references', 'deprecated', 'deprecation_date', 'release_date']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Iterate over each \"cpe-item\" element in the XML\n",
    "        for cpe_item in root.findall(\".//{http://cpe.mitre.org/dictionary/2.0}cpe-item\"):\n",
    "            # Extract the \"name\" attribute\n",
    "            cpe_name = cpe_item.attrib.get('name', 'N/A')\n",
    "\n",
    "            # Extract \"title\" elements (there can be multiple titles in different languages)\n",
    "            titles = cpe_item.findall(\".//{http://cpe.mitre.org/dictionary/2.0}title\")\n",
    "            title_texts = [title.text for title in titles if title.text]  # Collect all titles\n",
    "\n",
    "            # Extract \"notes\" elements\n",
    "            notes = cpe_item.findall(\".//{http://cpe.mitre.org/dictionary/2.0}notes\")\n",
    "            notes_texts = [note.text for note in notes if note.text]  # Collect all notes\n",
    "\n",
    "            # Extract \"references\" elements\n",
    "            references = cpe_item.findall(\".//{http://cpe.mitre.org/dictionary/2.0}reference\")\n",
    "            reference_texts = [ref.attrib.get('href', 'N/A') for ref in references]  # Collect reference hrefs\n",
    "\n",
    "            # Extract \"deprecated\" attribute and \"deprecation_date\" if present\n",
    "            deprecated = cpe_item.attrib.get('deprecated', 'false')\n",
    "            deprecation_date = cpe_item.attrib.get('deprecation_date', 'N/A')\n",
    "\n",
    "            # Write the data to CSV\n",
    "            writer.writerow({\n",
    "                'cpe_name': cpe_name,\n",
    "                'title': ', '.join(title_texts),\n",
    "                'notes': ', '.join(notes_texts),\n",
    "                'references': ', '.join(reference_texts),\n",
    "                'deprecated': deprecated,\n",
    "                'deprecation_date': deprecation_date,\n",
    "                'release_date': release_date\n",
    "            })\n",
    "    \n",
    "    print(f\"Data successfully written to {output_csv}\")\n",
    "\n",
    "# Example usage:\n",
    "process_cpe_data('../data/CPEs/official-cpe-dictionary_v2.3.xml', '../data/CPEs/cpe_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3eac477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def process_cve_data_per_json(json_root_dir, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Walk through the directory structure\n",
    "    for root, dirs, files in os.walk(json_root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                json_file_path = os.path.join(root, file)\n",
    "                print(f\"Processing {json_file_path}...\")\n",
    "                \n",
    "                # Create a CSV filename based on the JSON file name\n",
    "                csv_filename = f\"{os.path.splitext(file)[0]}.csv\"\n",
    "                csv_file_path = os.path.join(output_dir, csv_filename)\n",
    "                \n",
    "                # Open the CSV file for writing\n",
    "                with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "                    fieldnames = ['CVE_ID', 'Timestamp', 'CPE_URI', 'Version_Start', 'Version_End', 'CWE', 'Impact_BaseScore', 'Impact_Severity', 'Published_Date', 'Last_Modified_Date']\n",
    "                    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "                    \n",
    "                    # Write the header row\n",
    "                    writer.writeheader()\n",
    "\n",
    "                    # Process the JSON file\n",
    "                    with open(json_file_path, 'r') as f:\n",
    "                        cve_data = json.load(f)\n",
    "\n",
    "                        # Extract CVE data from each \"CVE_Items\" entry\n",
    "                        for item in cve_data.get('CVE_Items', []):\n",
    "                            cve_id = item['cve']['CVE_data_meta']['ID']\n",
    "                            timestamp = cve_data['CVE_data_timestamp']\n",
    "\n",
    "                            # Extract CWE(s) from the problemtype section\n",
    "                            cwes = []\n",
    "                            for problemtype_data in item['cve']['problemtype']['problemtype_data']:\n",
    "                                for desc in problemtype_data.get('description', []):\n",
    "                                    cwes.append(desc.get('value', 'N/A'))\n",
    "                            cwe_list = ', '.join(cwes) if cwes else 'None'\n",
    "\n",
    "                            # Extract matched CPEs from the configurations section\n",
    "                            for node in item.get('configurations', {}).get('nodes', []):\n",
    "                                for cpe_match in node.get('cpe_match', []):\n",
    "                                    cpe_uri = cpe_match.get('cpe23Uri', 'N/A')\n",
    "                                    version_start = cpe_match.get('versionStartIncluding', 'N/A')\n",
    "                                    version_end = cpe_match.get('versionEndIncluding', 'N/A')\n",
    "                                    \n",
    "                                    # Extract impact data (base score and severity)\n",
    "                                    base_score = 'N/A'\n",
    "                                    severity = 'N/A'\n",
    "                                    impact_v3 = item.get('impact', {}).get('baseMetricV3', {})\n",
    "                                    if impact_v3:\n",
    "                                        base_score = impact_v3.get('cvssV3', {}).get('baseScore', 'N/A')\n",
    "                                        severity = impact_v3.get('cvssV3', {}).get('baseSeverity', 'N/A')\n",
    "                                    \n",
    "                                    # Extract publishedDate and lastModifiedDate\n",
    "                                    published_date = item.get('publishedDate', 'N/A')\n",
    "                                    last_modified_date = item.get('lastModifiedDate', 'N/A')\n",
    "\n",
    "                                    # Write each CPE entry as a separate row\n",
    "                                    writer.writerow({\n",
    "                                        'CVE_ID': cve_id,\n",
    "                                        'Timestamp': timestamp,\n",
    "                                        'CPE_URI': cpe_uri,\n",
    "                                        'Version_Start': version_start,\n",
    "                                        'Version_End': version_end,\n",
    "                                        'CWE': cwe_list,\n",
    "                                        'Impact_BaseScore': base_score,\n",
    "                                        'Impact_Severity': severity,\n",
    "                                        'Published_Date': published_date,\n",
    "                                        'Last_Modified_Date': last_modified_date\n",
    "                                    })\n",
    "\n",
    "                print(f\"Data for {json_file_path} written to {csv_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a288cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_csv(file_path):\n",
    "    # Read the CSV file in chunks to handle large files\n",
    "    chunk_size = 1000  # Adjust based on memory availability\n",
    "    df_chunk = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "    \n",
    "    # Load only the first chunk to inspect the data\n",
    "    df = next(df_chunk)\n",
    "    \n",
    "    # Display the column names and first three rows\n",
    "    print(\"Columns:\", df.columns)\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39e76ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def preview_cwe_json(file_path):\n",
    "    # Open the JSON file and load the entire data\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            # Check if the data is a list of CWEs\n",
    "            if isinstance(data, list) and len(data) > 0:\n",
    "                # Preview the first three entries\n",
    "                print(\"Previewing the first 3 CWE entries:\")\n",
    "                for entry in data[:3]:\n",
    "                    print(f\"\\nCWE-ID: {entry.get('CWE-ID', 'N/A')}\")\n",
    "                    print(f\"Name: {entry.get('Name', 'N/A')}\")\n",
    "                    print(f\"Description: {entry.get('Description', 'N/A')}\")\n",
    "                    print(f\"Common Consequences:\")\n",
    "                    for consequence in entry.get('Common_Consequences', []):\n",
    "                        print(f\"  Scope: {consequence.get('Scope', 'N/A')}\")\n",
    "                        print(f\"  Impacts: {', '.join(consequence.get('Impacts', []))}\")\n",
    "                    print(f\"Related Weaknesses:\")\n",
    "                    for weakness in entry.get('Related_Weaknesses', []):\n",
    "                        print(f\"  Nature: {weakness.get('Nature', 'N/A')}\")\n",
    "                        print(f\"  CWE_ID: {weakness.get('CWE_ID', 'N/A')}\")\n",
    "            else:\n",
    "                print(\"The JSON data is not a list or is empty.\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ded34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpe_data = '../data/CPEs/cpe_data.csv'\n",
    "cve_data = '../data/CVEs/cveData.json'\n",
    "cwe_data = '../data/CWEs/cweData.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce8aed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data/CVEs/nvdcve-1.1-modified.json...\n",
      "Data for ../data/CVEs/nvdcve-1.1-modified.json written to ../data/CVEs/CSVs/nvdcve-1.1-modified.csv\n",
      "Processing ../data/CVEs/nvdcve-1.1-recent.json...\n",
      "Data for ../data/CVEs/nvdcve-1.1-recent.json written to ../data/CVEs/CSVs/nvdcve-1.1-recent.csv\n",
      "Processing ../data/CVEs/2009/nvdcve-1.1-2009.json...\n",
      "Data for ../data/CVEs/2009/nvdcve-1.1-2009.json written to ../data/CVEs/CSVs/nvdcve-1.1-2009.csv\n",
      "Processing ../data/CVEs/2022/nvdcve-1.1-2022.json...\n",
      "Data for ../data/CVEs/2022/nvdcve-1.1-2022.json written to ../data/CVEs/CSVs/nvdcve-1.1-2022.csv\n",
      "Processing ../data/CVEs/2010/nvdcve-1.1-2010.json...\n",
      "Data for ../data/CVEs/2010/nvdcve-1.1-2010.json written to ../data/CVEs/CSVs/nvdcve-1.1-2010.csv\n",
      "Processing ../data/CVEs/2020/nvdcve-1.1-2020.json...\n",
      "Data for ../data/CVEs/2020/nvdcve-1.1-2020.json written to ../data/CVEs/CSVs/nvdcve-1.1-2020.csv\n",
      "Processing ../data/CVEs/2011/nvdcve-1.1-2011.json...\n",
      "Data for ../data/CVEs/2011/nvdcve-1.1-2011.json written to ../data/CVEs/CSVs/nvdcve-1.1-2011.csv\n",
      "Processing ../data/CVEs/2008/nvdcve-1.1-2008.json...\n",
      "Data for ../data/CVEs/2008/nvdcve-1.1-2008.json written to ../data/CVEs/CSVs/nvdcve-1.1-2008.csv\n",
      "Processing ../data/CVEs/2005/nvdcve-1.1-2005.json...\n",
      "Data for ../data/CVEs/2005/nvdcve-1.1-2005.json written to ../data/CVEs/CSVs/nvdcve-1.1-2005.csv\n",
      "Processing ../data/CVEs/2002/nvdcve-1.1-2002.json...\n",
      "Data for ../data/CVEs/2002/nvdcve-1.1-2002.json written to ../data/CVEs/CSVs/nvdcve-1.1-2002.csv\n",
      "Processing ../data/CVEs/2013/nvdcve-1.1-2013.json...\n",
      "Data for ../data/CVEs/2013/nvdcve-1.1-2013.json written to ../data/CVEs/CSVs/nvdcve-1.1-2013.csv\n",
      "Processing ../data/CVEs/2015/nvdcve-1.1-2015.json...\n",
      "Data for ../data/CVEs/2015/nvdcve-1.1-2015.json written to ../data/CVEs/CSVs/nvdcve-1.1-2015.csv\n",
      "Processing ../data/CVEs/2003/nvdcve-1.1-2003.json...\n",
      "Data for ../data/CVEs/2003/nvdcve-1.1-2003.json written to ../data/CVEs/CSVs/nvdcve-1.1-2003.csv\n",
      "Processing ../data/CVEs/2024/nvdcve-1.1-2024.json...\n",
      "Data for ../data/CVEs/2024/nvdcve-1.1-2024.json written to ../data/CVEs/CSVs/nvdcve-1.1-2024.csv\n",
      "Processing ../data/CVEs/2014/nvdcve-1.1-2014.json...\n",
      "Data for ../data/CVEs/2014/nvdcve-1.1-2014.json written to ../data/CVEs/CSVs/nvdcve-1.1-2014.csv\n",
      "Processing ../data/CVEs/2006/nvdcve-1.1-2006.json...\n",
      "Data for ../data/CVEs/2006/nvdcve-1.1-2006.json written to ../data/CVEs/CSVs/nvdcve-1.1-2006.csv\n",
      "Processing ../data/CVEs/2007/nvdcve-1.1-2007.json...\n",
      "Data for ../data/CVEs/2007/nvdcve-1.1-2007.json written to ../data/CVEs/CSVs/nvdcve-1.1-2007.csv\n",
      "Processing ../data/CVEs/2021/nvdcve-1.1-2021.json...\n",
      "Data for ../data/CVEs/2021/nvdcve-1.1-2021.json written to ../data/CVEs/CSVs/nvdcve-1.1-2021.csv\n",
      "Processing ../data/CVEs/2012/nvdcve-1.1-2012.json...\n",
      "Data for ../data/CVEs/2012/nvdcve-1.1-2012.json written to ../data/CVEs/CSVs/nvdcve-1.1-2012.csv\n",
      "Processing ../data/CVEs/2019/nvdcve-1.1-2019.json...\n",
      "Data for ../data/CVEs/2019/nvdcve-1.1-2019.json written to ../data/CVEs/CSVs/nvdcve-1.1-2019.csv\n",
      "Processing ../data/CVEs/2017/nvdcve-1.1-2017.json...\n",
      "Data for ../data/CVEs/2017/nvdcve-1.1-2017.json written to ../data/CVEs/CSVs/nvdcve-1.1-2017.csv\n",
      "Processing ../data/CVEs/2018/nvdcve-1.1-2018.json...\n",
      "Data for ../data/CVEs/2018/nvdcve-1.1-2018.json written to ../data/CVEs/CSVs/nvdcve-1.1-2018.csv\n",
      "Processing ../data/CVEs/2004/nvdcve-1.1-2004.json...\n",
      "Data for ../data/CVEs/2004/nvdcve-1.1-2004.json written to ../data/CVEs/CSVs/nvdcve-1.1-2004.csv\n",
      "Processing ../data/CVEs/2016/nvdcve-1.1-2016.json...\n",
      "Data for ../data/CVEs/2016/nvdcve-1.1-2016.json written to ../data/CVEs/CSVs/nvdcve-1.1-2016.csv\n",
      "Processing ../data/CVEs/2023/nvdcve-1.1-2023.json...\n",
      "Data for ../data/CVEs/2023/nvdcve-1.1-2023.json written to ../data/CVEs/CSVs/nvdcve-1.1-2023.csv\n"
     ]
    }
   ],
   "source": [
    "# process_cve_data('../data/CVEs/', '../data/CVEs/cve_data_output.csv')\n",
    "process_cve_data_per_json('../data/CVEs/', '../data/CVEs/CSVs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b509bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpe_name</th>\n",
       "      <th>title</th>\n",
       "      <th>notes</th>\n",
       "      <th>references</th>\n",
       "      <th>deprecated</th>\n",
       "      <th>deprecation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cpe:/a:%240.99_kindle_books_project:%240.99_ki...</td>\n",
       "      <td>$0.99 Kindle Books project $0.99 Kindle Books ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://play.google.com/store/apps/details?id=...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cpe:/a:%40nubosoftware%2fnode-static_project:%...</td>\n",
       "      <td>@nubosoftware/node-static Project @nubosoftwar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.npmjs.com/package/@nubosoftware/no...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cpe:/a:%40thi.ng%2fegf_project:%40thi.ng%2fegf...</td>\n",
       "      <td>@thi.ng/egf Project @thi.ng/egf for Node.js</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/thi-ng/umbrella/security/ad...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cpe_name  \\\n",
       "0  cpe:/a:%240.99_kindle_books_project:%240.99_ki...   \n",
       "1  cpe:/a:%40nubosoftware%2fnode-static_project:%...   \n",
       "2  cpe:/a:%40thi.ng%2fegf_project:%40thi.ng%2fegf...   \n",
       "\n",
       "                                               title  notes  \\\n",
       "0  $0.99 Kindle Books project $0.99 Kindle Books ...    NaN   \n",
       "1  @nubosoftware/node-static Project @nubosoftwar...    NaN   \n",
       "2        @thi.ng/egf Project @thi.ng/egf for Node.js    NaN   \n",
       "\n",
       "                                          references  deprecated  \\\n",
       "0  https://play.google.com/store/apps/details?id=...       False   \n",
       "1  https://www.npmjs.com/package/@nubosoftware/no...       False   \n",
       "2  https://github.com/thi-ng/umbrella/security/ad...       False   \n",
       "\n",
       "  deprecation_date  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(cpe_data)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "156c0d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320456"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba705d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previewing the first 3 CWE entries:\n",
      "\n",
      "CWE-ID: 5\n",
      "Name: J2EE Misconfiguration: Data Transmission Without Encryption\n",
      "Description: Information sent over a network can be compromised while in transit. An attacker may be able to read or modify the contents if the data are sent in plaintext or are weakly encrypted.The product configuration should ensure that SSL or an encryption mechanism of equivalent strength and vetted reputation is used for all access-controlled pages.\n",
      "Common Consequences:\n",
      "  Scope: Confidentiality\n",
      "  Impacts: Read Application Data\n",
      "  Scope: Integrity\n",
      "  Impacts: Modify Application Data\n",
      "Related Weaknesses:\n",
      "  Nature: ChildOf\n",
      "  CWE_ID: 319\n",
      "\n",
      "CWE-ID: 6\n",
      "Name: J2EE Misconfiguration: Insufficient Session-ID Length\n",
      "Description: The J2EE application is configured to use an insufficient session ID length.Session identifiers should be at least 128 bits long to prevent brute-force session guessing. A shorter session identifier leaves the application open to brute-force session guessing attacks.A lower bound on the number of valid session identifiers that are available to be guessed is the number of users that are active on a site at any given moment. However, any users that abandon their sessions without logging out will increase this number. (This is one of many good reasons to have a short inactive session timeout.) With a 64 bit session identifier, assume 32 bits of entropy. For a large web site, assume that the attacker can try 1,000 guesses per second and that there are 10,000 valid session identifiers at any given moment. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is less than 4 minutes. Now assume a 128 bit session identifier that provides 64 bits of entropy. With a very large web site, an attacker might try 10,000 guesses per second with 100,000 valid session identifiers available to be guessed. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is greater than 292 years.\n",
      "Common Consequences:\n",
      "  Scope: Access Control\n",
      "  Impacts: Gain Privileges or Assume Identity\n",
      "Related Weaknesses:\n",
      "  Nature: ChildOf\n",
      "  CWE_ID: 334\n",
      "\n",
      "CWE-ID: 7\n",
      "Name: J2EE Misconfiguration: Missing Custom Error Page\n",
      "Description: The default error page of a web application should not display sensitive information about the product.Handle exceptions appropriately in source code.Always define appropriate error pages. The application configuration should specify a default error page in order to guarantee that the application will never leak error messages to an attacker. Handling standard HTTP error codes is useful and user-friendly in addition to being a good security practice, and a good configuration will also define a last-chance error handler that catches any exception that could possibly be thrown by the application.Do not attempt to process an error or attempt to mask it.Verify return values are correct and do not supply sensitive information about the system.\n",
      "Common Consequences:\n",
      "  Scope: Confidentiality\n",
      "  Impacts: Read Application Data\n",
      "Related Weaknesses:\n",
      "  Nature: ChildOf\n",
      "  CWE_ID: 756\n"
     ]
    }
   ],
   "source": [
    "preview_cwe_json(cwe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5601b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON data is not a list or is empty.\n"
     ]
    }
   ],
   "source": [
    "preview_cwe_json(cve_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1570e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
